# 01 - Computer Architecture

Understanding how computers work at the hardware level - the foundation for all performance optimization.

## ğŸ“ Directory Structure

```
01-computer-architecture/
â”œâ”€â”€ 01-binary-and-bits/       # Binary, floating point, bit ops
â”‚   â”œâ”€â”€ 01_binary_basics.c
â”‚   â”œâ”€â”€ 02_floating_point.c
â”‚   â”œâ”€â”€ 03_bit_operations.c
â”‚   â””â”€â”€ 04_endianness.c
â”œâ”€â”€ 02-memory-hierarchy/      # Caching, blocking, prefetch
â”‚   â”œâ”€â”€ 01_cache_basics.c
â”‚   â”œâ”€â”€ 02_cache_blocking.c
â”‚   â”œâ”€â”€ 03_prefetching.c
â”‚   â””â”€â”€ 04_false_sharing.c
â”œâ”€â”€ 03-simd-vectorization/    # SSE, AVX, vectorization
â”‚   â””â”€â”€ 01_simd_basics.c
â”œâ”€â”€ 04-memory-alignment/      # Alignment for CPU/GPU
â”‚   â””â”€â”€ 01_alignment_basics.c
â”œâ”€â”€ 05-cpu-pipeline/          # ILP, branch prediction
â”‚   â””â”€â”€ 01_pipeline_basics.c
â”œâ”€â”€ 06-data-layout/           # AoS vs SoA, tensor layouts
â”‚   â””â”€â”€ 01_soa_vs_aos.c
â””â”€â”€ 07-benchmarking/          # Correct measurement
    â””â”€â”€ 01_benchmark_basics.c
```

## ğŸ“š Topics Covered

### CPU Fundamentals
- **Von Neumann Architecture**: Fetch-decode-execute cycle
- **Pipelining**: Instruction-level parallelism, hazards
- **Superscalar Execution**: Multiple execution units
- **Branch Prediction**: Speculative execution
- **Out-of-Order Execution**: Tomasulo's algorithm

### Memory Hierarchy
- **Registers**: Fastest storage, limited quantity
- **Cache Levels**: L1, L2, L3 cache design
- **Cache Coherency**: MESI protocol, false sharing
- **DRAM**: Row buffers, bank conflicts
- **Virtual Memory**: Page tables, TLB

### Instruction Set Architecture (ISA)
- **RISC vs CISC**: Design philosophies
- **x86-64**: Intel/AMD architecture
- **ARM**: Mobile and server ARM processors
- **RISC-V**: Open-source ISA

### Modern CPU Features
- **SIMD**: SSE, AVX, AVX-512, NEON
- **Vector Processing**: Data parallelism
- **Hardware Prefetching**: Automatic data loading
- **Memory Ordering**: Memory barriers, atomics

## ğŸ¯ Learning Objectives

- [ ] Explain the fetch-decode-execute cycle
- [ ] Understand cache hierarchy and locality
- [ ] Identify pipeline hazards
- [ ] Use SIMD instructions for vectorization
- [ ] Analyze memory access patterns

## ğŸ’» Practical Exercises

1. Write a program that demonstrates cache effects
2. Measure memory bandwidth at different levels
3. Implement matrix multiply with SIMD
4. Profile branch mispredictions

## ğŸ“– Resources

### Books
- "Computer Architecture: A Quantitative Approach" - Hennessy & Patterson
- "Computer Systems: A Programmer's Perspective" - Bryant & O'Hallaron

### Online
- MIT 6.004 Computation Structures
- Computer Architecture course by Onur Mutlu (CMU)

## ğŸ“ Structure

```
01-computer-architecture/
â”œâ”€â”€ cpu-fundamentals/
â”‚   â”œâ”€â”€ pipelining/
â”‚   â”œâ”€â”€ branch-prediction/
â”‚   â””â”€â”€ superscalar/
â”œâ”€â”€ memory-hierarchy/
â”‚   â”œâ”€â”€ caching/
â”‚   â”œâ”€â”€ virtual-memory/
â”‚   â””â”€â”€ cache-coherency/
â”œâ”€â”€ isa/
â”‚   â”œâ”€â”€ x86-64/
â”‚   â”œâ”€â”€ arm/
â”‚   â””â”€â”€ risc-v/
â””â”€â”€ simd-vectorization/
    â”œâ”€â”€ sse-avx/
    â””â”€â”€ neon/
```

## â±ï¸ Estimated Time: 4-6 weeks
