# 11 - GPU Architecture

Understanding NVIDIA GPU internals before CUDA programming.

## ğŸ“š Topics Covered

### GPU vs CPU
- **Throughput vs Latency**: Design philosophies
- **SIMT**: Single Instruction Multiple Threads
- **Massive Parallelism**: Thousands of cores
- **Memory Bandwidth**: 10x+ more than CPU

### NVIDIA Architecture Evolution
- **Fermi**: First modern architecture
- **Kepler/Maxwell**: Power efficiency
- **Pascal**: Unified memory, NVLink
- **Volta/Turing**: Tensor Cores, mixed precision
- **Ampere**: 3rd gen Tensor Cores, sparsity
- **Hopper**: Transformer Engine, TMA
- **Blackwell**: Latest generation

### Streaming Multiprocessor (SM)
- **CUDA Cores**: FP32, INT32 units
- **Tensor Cores**: Matrix multiply accelerators
- **Warp Schedulers**: Instruction dispatch
- **Register File**: Per-SM registers
- **Shared Memory**: Programmer-managed cache
- **L1 Cache**: Combined with shared memory

### Memory Hierarchy
- **Registers**: Fastest, limited per thread
- **Shared Memory**: Per-block, explicit
- **L1/L2 Cache**: Automatic caching
- **Global Memory**: HBM, high bandwidth
- **Constant Memory**: Read-only, cached
- **Texture Memory**: Spatial locality

### Execution Model
- **Threads, Warps, Blocks**: Hierarchy
- **Warp Execution**: 32 threads SIMT
- **Occupancy**: Active warps per SM
- **Latency Hiding**: Many warps in flight

## ğŸ¯ Learning Objectives

- [ ] Understand SM architecture
- [ ] Calculate theoretical performance
- [ ] Know memory hierarchy trade-offs
- [ ] Analyze occupancy

## ğŸ’» Practical Exercises

1. Calculate roofline model limits
2. Analyze occupancy calculator
3. Compare GPU generations
4. Study architecture diagrams

## ğŸ“– Resources

### Whitepapers
- NVIDIA GPU Architecture whitepapers
- "Dissecting the NVIDIA Volta/Turing Architecture"

### Online
- NVIDIA Developer Blog
- GPU Mode lectures

## ğŸ“ Structure

```
11-gpu-architecture/
â”œâ”€â”€ fundamentals/
â”‚   â”œâ”€â”€ gpu-vs-cpu/
â”‚   â”œâ”€â”€ simt/
â”‚   â””â”€â”€ history/
â”œâ”€â”€ nvidia-architectures/
â”‚   â”œâ”€â”€ ampere/
â”‚   â”œâ”€â”€ hopper/
â”‚   â””â”€â”€ blackwell/
â”œâ”€â”€ sm-internals/
â”‚   â”œâ”€â”€ cuda-cores/
â”‚   â”œâ”€â”€ tensor-cores/
â”‚   â””â”€â”€ warp-schedulers/
â”œâ”€â”€ memory-hierarchy/
â”‚   â”œâ”€â”€ registers/
â”‚   â”œâ”€â”€ shared-memory/
â”‚   â”œâ”€â”€ global-memory/
â”‚   â””â”€â”€ caches/
â””â”€â”€ execution-model/
    â”œâ”€â”€ warps/
    â”œâ”€â”€ occupancy/
    â””â”€â”€ latency-hiding/
```

## â±ï¸ Estimated Time: 2-3 weeks
