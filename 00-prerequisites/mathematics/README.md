# Mathematics for Systems & ML

## Linear Algebra
Essential for understanding:
- Matrix operations in ML
- GPU kernel implementations
- Memory layout (row-major vs column-major)

### Key Topics
- Matrix multiplication (GEMM)
- Eigenvalues/eigenvectors
- SVD decomposition
- Tensor operations

## Numerical Methods
- Floating-point representation (IEEE 754)
- Numerical stability
- Precision (FP32, FP16, BF16, FP8)
- Rounding modes

## Resources
- 3Blue1Brown Linear Algebra series
- Numerical Recipes (book)
