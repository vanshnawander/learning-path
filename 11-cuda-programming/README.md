# 12 - CUDA Programming

The foundation of GPU programming for NVIDIA GPUs.

## ğŸ“š Topics Covered

### CUDA Basics
- **Kernels**: __global__, __device__, __host__
- **Thread Hierarchy**: threadIdx, blockIdx, blockDim
- **Memory Allocation**: cudaMalloc, cudaMemcpy
- **Error Handling**: cudaGetLastError
- **Synchronization**: cudaDeviceSynchronize

### Thread Organization
- **Grid and Block Dimensions**: 1D, 2D, 3D
- **Warp Size**: 32 threads
- **Cooperative Groups**: Flexible synchronization
- **Thread Divergence**: Performance impact

### Memory Management
- **Global Memory**: Coalesced access patterns
- **Shared Memory**: Bank conflicts
- **Constant Memory**: Broadcast reads
- **Texture Memory**: 2D locality
- **Unified Memory**: Automatic migration
- **Pinned Memory**: DMA transfers

### Optimization Techniques
- **Occupancy**: Maximizing active warps
- **Memory Coalescing**: Aligned, strided access
- **Bank Conflicts**: Shared memory access
- **Instruction-Level Parallelism**: ILP
- **Loop Unrolling**: Reducing overhead
- **Warp-Level Primitives**: Shuffle, vote

### Advanced CUDA
- **Streams**: Concurrent execution
- **Events**: Timing, synchronization
- **Dynamic Parallelism**: Kernels launching kernels
- **Multi-GPU**: Peer-to-peer, NVLink
- **PTX Assembly**: Low-level optimization

### cuBLAS, cuDNN
- **cuBLAS**: BLAS on GPU
- **cuDNN**: Deep learning primitives
- **CUTLASS**: Template library for GEMM
- **cuSPARSE**: Sparse operations

## ğŸ¯ Learning Objectives

- [ ] Write correct CUDA kernels
- [ ] Optimize memory access patterns
- [ ] Use shared memory effectively
- [ ] Profile with Nsight

## ğŸ’» Practical Exercises

1. Implement vector addition
2. Write optimized matrix multiply
3. Implement parallel reduction
4. Profile and optimize a kernel

## ğŸ“– Resources

### Books
- "Programming Massively Parallel Processors" - Kirk & Hwu
- CUDA C Programming Guide (NVIDIA)

### Online
- NVIDIA CUDA samples
- GPU Mode lectures

## ğŸ“ Structure

```
12-cuda-programming/
â”œâ”€â”€ basics/
â”‚   â”œâ”€â”€ hello-world/
â”‚   â”œâ”€â”€ thread-hierarchy/
â”‚   â””â”€â”€ memory-allocation/
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ global-memory/
â”‚   â”œâ”€â”€ shared-memory/
â”‚   â”œâ”€â”€ unified-memory/
â”‚   â””â”€â”€ pinned-memory/
â”œâ”€â”€ optimization/
â”‚   â”œâ”€â”€ coalescing/
â”‚   â”œâ”€â”€ occupancy/
â”‚   â”œâ”€â”€ bank-conflicts/
â”‚   â””â”€â”€ warp-primitives/
â”œâ”€â”€ advanced/
â”‚   â”œâ”€â”€ streams/
â”‚   â”œâ”€â”€ multi-gpu/
â”‚   â””â”€â”€ ptx/
â””â”€â”€ libraries/
    â”œâ”€â”€ cublas/
    â”œâ”€â”€ cudnn/
    â””â”€â”€ cutlass/
```

## â±ï¸ Estimated Time: 6-8 weeks
